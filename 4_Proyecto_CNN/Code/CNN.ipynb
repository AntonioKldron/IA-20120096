{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:34: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:34: SyntaxWarning: invalid escape sequence '\\.'\n",
      "C:\\Users\\Antonio\\AppData\\Local\\Temp\\ipykernel_29620\\1833321847.py:34: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  if re.search(\"\\.(jpg|jpeg|png|bmp|tiff)$\", filename):\n",
      "C:\\Users\\Antonio\\AppData\\Local\\Temp\\ipykernel_29620\\1833321847.py:34: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  if re.search(\"\\.(jpg|jpeg|png|bmp|tiff)$\", filename):\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "#from keras.layers import Conv2D, MaxPooling2D\n",
    "#from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    BatchNormalization, SeparableConv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense, Conv2D\n",
    ")\n",
    "from keras.layers import LeakyReLU\n",
    "\n",
    "\n",
    "dirname = os.path.join(os.getcwd(), 'eventos')\n",
    "imgpath = dirname + os.sep\n",
    "\n",
    "images = []\n",
    "directories = []\n",
    "dircount = []\n",
    "prevRoot = ''\n",
    "cant = 0\n",
    "\n",
    "print(\"leyendo imagenes de \", imgpath)\n",
    "\n",
    "for root, dirnames, filenames in os.walk(imgpath):\n",
    "    for filename in filenames:\n",
    "        if re.search(\"\\.(jpg|jpeg|png|bmp|tiff)$\", filename):\n",
    "            cant = cant + 1\n",
    "            filepath = os.path.join(root, filename)\n",
    "            image = plt.imread(filepath)\n",
    "            if len(image.shape) == 3:\n",
    "                images.append(image)\n",
    "            b = \"Leyendo...\" + str(cant)\n",
    "            print(b, end=\"\\r\")\n",
    "            if prevRoot != root:\n",
    "                print(root, cant)\n",
    "                prevRoot = root\n",
    "                directories.append(root)\n",
    "                dircount.append(cant)\n",
    "                cant = 0\n",
    "dircount.append(cant)\n",
    "\n",
    "dircount = dircount[1:]\n",
    "dircount[0] = dircount[0] + 1\n",
    "print('Directorios leidos:', len(directories))\n",
    "print(\"Imagenes en cada directorio\", dircount)\n",
    "print('suma Total de imagenes en subdirs:', sum(dircount))\n",
    "\n",
    "labels = []\n",
    "indice = 0\n",
    "for cantidad in dircount:\n",
    "    for i in range(cantidad):\n",
    "        labels.append(indice)\n",
    "    indice = indice + 1\n",
    "print(\"Cantidad etiquetas creadas: \", len(labels))\n",
    "\n",
    "eventos = []\n",
    "indice = 0\n",
    "for directorio in directories:\n",
    "    name = directorio.split(os.sep)\n",
    "    print(indice, name[len(name) - 1])\n",
    "    eventos.append(name[len(name) - 1])\n",
    "    indice = indice + 1\n",
    "\n",
    "y = np.array(labels)\n",
    "X = np.array(images, dtype=np.uint8)  # convierto de lista a numpy\n",
    "\n",
    "# Find the unique numbers from the train labels\n",
    "classes = np.unique(y)\n",
    "nClasses = len(classes)\n",
    "print('Total number of outputs : ', nClasses)\n",
    "print('Output classes : ', classes)\n",
    "\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(X, y, test_size=0.2)\n",
    "print('Training data shape : ', train_X.shape, train_Y.shape)\n",
    "print('Testing data shape : ', test_X.shape, test_Y.shape)\n",
    "\n",
    "plt.figure(figsize=[5, 5])\n",
    "\n",
    "# Display the first image in training data\n",
    "plt.subplot(121)\n",
    "plt.imshow(train_X[0, :, :], cmap='gray')\n",
    "plt.title(\"Ground Truth : {}\".format(train_Y[0]))\n",
    "\n",
    "# Display the first image in testing data\n",
    "plt.subplot(122)\n",
    "plt.imshow(test_X[0, :, :], cmap='gray')\n",
    "plt.title(\"Ground Truth : {}\".format(test_Y[0]))\n",
    "\n",
    "train_X = train_X.astype('float32')\n",
    "test_X = test_X.astype('float32')\n",
    "train_X = train_X / 255.\n",
    "test_X = test_X / 255.\n",
    "plt.imshow(test_X[0, :, :])\n",
    "\n",
    "# Change the labels from categorical to one-hot encoding\n",
    "train_Y_one_hot = to_categorical(train_Y)\n",
    "test_Y_one_hot = to_categorical(test_Y)\n",
    "\n",
    "# Display the change for category label using one-hot encoding\n",
    "print('Original label:', train_Y[0])\n",
    "print('After conversion to one-hot:', train_Y_one_hot[0])\n",
    "\n",
    "# Mezclar todo y crear los grupos de entrenamiento y testing\n",
    "train_X, valid_X, train_label, valid_label = train_test_split(train_X, train_Y_one_hot, test_size=0.2, random_state=13)\n",
    "\n",
    "print(train_X.shape, valid_X.shape, train_label.shape, valid_label.shape)\n",
    "\n",
    "# declaramos variables con los parámetros de configuración de la red\n",
    "INIT_LR = 1e-3  # Valor inicial de learning rate. El valor 1e-3 corresponde con 0.001\n",
    "epochs = 20  # Cantidad de iteraciones completas al conjunto de imagenes de entrenamiento\n",
    "batch_size = 64  # cantidad de imágenes que se toman a la vez en memoria\n",
    "\n",
    "evento_model = Sequential()\n",
    "evento_model.add(Conv2D(32, kernel_size=(3, 3), activation='linear', padding='same', input_shape=(28, 28, 3)))\n",
    "evento_model.add(LeakyReLU(alpha=0.1))\n",
    "evento_model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "evento_model.add(Dropout(0.5))\n",
    "\n",
    "evento_model.add(Flatten())\n",
    "evento_model.add(Dense(32, activation='linear'))\n",
    "evento_model.add(LeakyReLU(alpha=0.1))\n",
    "evento_model.add(Dropout(0.5))\n",
    "evento_model.add(Dense(nClasses, activation='softmax'))\n",
    "\n",
    "evento_model.summary()\n",
    "\n",
    "evento_model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                     optimizer=tf.keras.optimizers.SGD(learning_rate=INIT_LR, decay=INIT_LR / 100),\n",
    "                     metrics=['accuracy'])\n",
    "# este paso puede tomar varios minutos, dependiendo de tu ordenador, cpu y memoria ram libre\n",
    "evento_train = evento_model.fit(train_X, train_label, batch_size=batch_size, epochs=epochs, verbose=1,\n",
    "                                validation_data=(valid_X, valid_label))\n",
    "\n",
    "# guardamos la red, para reutilizarla en el futuro, sin tener que volver a entrenar\n",
    "evento_model.save(\"catastrofe.h5\")\n",
    "\n",
    "test_eval = evento_model.evaluate(test_X, test_Y_one_hot, verbose=1)\n",
    "\n",
    "print('Test loss:', test_eval[0])\n",
    "print('Test accuracy:', test_eval[1])\n",
    "\n",
    "evento_train.history\n",
    "\n",
    "accuracy = evento_train.history['accuracy']\n",
    "val_accuracy = evento_train.history['val_accuracy']\n",
    "loss = evento_train.history['loss']\n",
    "val_loss = evento_train.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "predicted_classes2 = evento_model.predict(test_X)\n",
    "\n",
    "predicted_classes = []\n",
    "for predicted_sport in predicted_classes2:\n",
    "    predicted_classes.append(predicted_sport.tolist().index(max(predicted_sport)))\n",
    "predicted_classes = np.array(predicted_classes)\n",
    "\n",
    "predicted_classes.shape, test_Y.shape\n",
    "\n",
    "correct = np.where(predicted_classes == test_Y)[0]\n",
    "print(\"Found %d correct labels\" % len(correct))\n",
    "for i, correct in enumerate(correct[0:9]):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(test_X[correct].reshape(28, 28, 3), cmap='gray', interpolation='none')\n",
    "    plt.title(\"{}, {}\".format(eventos[predicted_classes[correct]],\n",
    "                              eventos[test_Y[correct]]))\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "incorrect = np.where(predicted_classes != test_Y)[0]\n",
    "print(\"Found %d incorrect labels\" % len(incorrect))\n",
    "for i, incorrect in enumerate(incorrect[0:9]):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(test_X[incorrect].reshape(28, 28, 3), cmap='gray', interpolation='none')\n",
    "    plt.title(\"{}, {}\".format(eventos[predicted_classes[incorrect]],\n",
    "                              eventos[test_Y[incorrect]]))\n",
    "    plt.tight_layout()\n",
    "\n",
    "target_names = [\"Class {}\".format(i) for i in range(nClasses)]\n",
    "print(classification_report(test_Y, predicted_classes, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entornoIA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
